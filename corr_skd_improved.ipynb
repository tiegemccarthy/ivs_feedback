{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import MySQLdb as mariadb\n",
    "from astropy.io import ascii\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/19JAN02XA/History/19JAN02XA_V000_kMk4.hist') as file:\n",
    "    contents = file.read()\n",
    "    section = contents.split('+')\n",
    "    \n",
    "with open(os.getcwd()+'/skd_files/r1875.skd') as file:\n",
    "    skd_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droppedChannels(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    dropped_chans = []\n",
    "    for ant in station_id[1]:\n",
    "        regex = ant + '.*'\n",
    "        dropped = re.findall(regex,text_section,re.MULTILINE)\n",
    "        if dropped == []:\n",
    "            dropped_chans.append('')            \n",
    "        elif len(dropped[0]) < 4:\n",
    "            dropped_chans.append('')\n",
    "        else:\n",
    "            dropped_chans.append(dropped)\n",
    "    return dropped_chans  \n",
    "    # This function takes a block of text, and scrapes out whether any AuScope antennas have dropped channels\n",
    "    # The input of this function is a text section from the correlator report (section[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualPcal(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    manual_pcal = []\n",
    "    for ant in station_id[1]:\n",
    "        if ant in text_section:\n",
    "            manual_pcal.append(True)\n",
    "        else:\n",
    "            manual_pcal.append(False)\n",
    "    return manual_pcal\n",
    "    # this determines whether manual pcal happened for any of our telescopes.\n",
    "    # The input of this function is a text section from the correlator report (section[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auscope_station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "sefd_stations = ['q', 'Q', 'a', 'K', 'I', 'N', 'X', 'j', 'W', 'i', 'B', 'b', 'd', 'H', 'T', 'E', 'u', 'V', 'Y', 'R']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mask for only the rows that are relevant for auscope antennas\n",
    "col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "snr_data = ascii.read(section[10], data_start=4, fast_reader=True, names=col_names)\n",
    "valid_rows = []\n",
    "for i in range(0, len(snr_data[:]['bl'])):\n",
    "    if any(char in snr_data[i]['bl'] for char in sefd_stations):\n",
    "        valid_rows.append(i)\n",
    "sefd_data = snr_data[valid_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sefdTableExtract(text_section):\n",
    "    sefd_stations = ['q', 'Q', 'a', 'K', 'I', 'N', 'X', 'j', 'W', 'i', 'B', 'b', 'd', 'H', 'T', 'E', 'u', 'V', 'Y', 'R']\n",
    "    col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "    snr_data = ascii.read(text_section, data_start=4, fast_reader=True, names=col_names)\n",
    "    valid_rows = []\n",
    "    for i in range(0, len(snr_data[:]['bl'])):\n",
    "        if any(char in snr_data[i]['bl'] for char in sefd_stations):\n",
    "            valid_rows.append(i)\n",
    "    sefd_data = snr_data[valid_rows]\n",
    "    return sefd_data\n",
    "    # This extracts the sefd ratio table for any of the 20 telescopes defined in the sefd estimation function.\n",
    "    # Make sure if you change which stations you want to be apart of the calculations, change this sefd_stations\n",
    "    # array and the one in the sefd estimator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HART15M', 'Ht', 'q'],\n",
       " ['ISHIOKA', 'Is', 'Q'],\n",
       " ['KATH12M', 'Ke', 'a'],\n",
       " ['KOKEE', 'Kk', 'K'],\n",
       " ['MATERA', 'Ma', 'I'],\n",
       " ['NYALES20', 'Ny', 'N'],\n",
       " ['ONSALA60', 'On', 'X'],\n",
       " ['SEJONG', 'Kv', 'j'],\n",
       " ['WETTZ13N', 'Wn', 'W'],\n",
       " ['YARRA12M', 'Yg', 'i']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = section[4]\n",
    "regex = '^\\s{1}([^\\s].*)'\n",
    "antennas_corr_report = re.findall(regex,contents,re.MULTILINE)\n",
    "\n",
    "antennas_corr_reference = []\n",
    "for line in antennas_corr_report:\n",
    "    line = line.split()\n",
    "    ref = [line[0], line[1][1:3], line[1][4]]\n",
    "    antennas_corr_reference.append(ref)\n",
    "\n",
    "antennas_corr_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antennaReference_CORR(text_section):\n",
    "    regex = '^\\s{1}([^\\s].*)'\n",
    "    antennas_corr_report = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antennas_corr_reference = []\n",
    "    for line in antennas_corr_report:\n",
    "        line = line.split()\n",
    "        ref = [line[0], line[1][1:3], line[1][4]]\n",
    "        antennas_corr_reference.append(ref)\n",
    "    return antennas_corr_reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['HART15M', 'Ht', 'Ht'], ['ISHIOKA', 'Is', 'Is'], ['KATH12M', 'Ke', 'Ke'], ['KOKEE', 'Kk', '102'], ['MATERA', 'Ma', '119'], ['NYALES20', 'Ny', '66'], ['ONSALA60', 'On', '02'], ['SEJONG', 'Kv', 'Kv'], ['WETTZ13N', 'Wn', 'Wn'], ['YARRA12M', 'Yg', 'Yg']]\n"
     ]
    }
   ],
   "source": [
    "regex = \"^A\\s\\s.*\"\n",
    "alias_reference = re.findall(regex,skd_contents,re.MULTILINE)\n",
    "\n",
    "\n",
    "antenna_reference = []\n",
    "for entry in alias_reference:\n",
    "    entry = entry.split()\n",
    "    ref = [entry[2], entry[14], entry[15]]\n",
    "    antenna_reference.append(ref)\n",
    "\n",
    "print(antenna_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antennaReference_SKD(text_section):\n",
    "    regex = \"^A\\s\\s.*\"\n",
    "    alias_reference = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antenna_reference = []\n",
    "    for entry in alias_reference:\n",
    "        entry = entry.split()\n",
    "        ref = [entry[2], entry[14], entry[15]]\n",
    "        antenna_reference.append(ref)\n",
    "    return antenna_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ht', '1400', '1050'], ['Is', '1950', '1750'], ['Ke', '4800', '4800'], ['Kk', '2000', '750'], ['Ma', '1600', '2200'], ['Ny', '1000', '1500'], ['On', '2000', '2500'], ['Kv', '5000', '5000'], ['Wn', '1400', '1050'], ['Yg', '5800', '4300']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regex_sefd = \"^T\\s{3}.*\"\n",
    "sefd_skd = re.findall(regex_sefd,skd_contents,re.MULTILINE)\n",
    "\n",
    "stations_SEFD =[]\n",
    "for line in sefd_skd:\n",
    "    line = line.split()\n",
    "    for i in range(0, len(antenna_reference)):\n",
    "        if line[1] in antenna_reference[i]:\n",
    "            SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "            stations_SEFD.append(SEFD_X_S)\n",
    "print(stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictedSEFDextract(text_section, antenna_reference):\n",
    "    regex_sefd = \"^T\\s{3}.*\"\n",
    "    sefd_skd = re.findall(regex_sefd,text_section,re.MULTILINE)\n",
    "    stations_SEFD =[]\n",
    "    for line in sefd_skd:\n",
    "        line = line.split()\n",
    "        for i in range(0, len(antenna_reference)):\n",
    "            if line[1] in antenna_reference[i]:\n",
    "                SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "                stations_SEFD.append(SEFD_X_S)\n",
    "    return stations_SEFD\n",
    "    # This block of code grabs all the SEFD setting lines and pulls the X and S SEFD for each station.\n",
    "    # It returns a list with each element containing [StationCode, SEFD_X, SEFD_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_sefd_x = []\n",
    "bl_sefd_s = []\n",
    "bl_const_x = []\n",
    "bl_const_s = []\n",
    "for i1 in range(0, len(snr_data)):\n",
    "    bl = snr_data[i1][0]\n",
    "    sefd_x = []\n",
    "    sefd_s = []\n",
    "    for i2 in range(0, len(antennas_corr_reference)):\n",
    "        if antennas_corr_reference[i2][2] in bl:\n",
    "            for j in range(0, len(stations_SEFD)):\n",
    "                if antennas_corr_reference[i2][1] in stations_SEFD[j][0]:\n",
    "                    sefd_x.append(stations_SEFD[j][1])\n",
    "                    sefd_s.append(stations_SEFD[j][2])\n",
    "    bl_sefd_x.append(sefd_x)\n",
    "    bl_sefd_s.append(sefd_s)\n",
    "    if snr_data[i1][1] == 0:\n",
    "        const_x = 0#float('NaN')\n",
    "    else: \n",
    "        const_x = (int(sefd_x[0])*int(sefd_x[1]))/snr_data[i1][1]  \n",
    "    if snr_data[i1][3] == 0:\n",
    "        const_s = 0#float('NaN')\n",
    "    else:\n",
    "        const_s = (int(sefd_s[0])*int(sefd_s[1]))/snr_data[i1][3] \n",
    "    bl_const_x.append(const_x)\n",
    "    bl_const_s.append(const_s)\n",
    "            \n",
    "# This nightmare spaghetti calculates the constant for each baseline combination in the SEFD equation\n",
    "# This constant is just (SEFD_pred_1 * SEFD_pred_2)/r_snr_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD):\n",
    "    bl_sefd_x = []\n",
    "    bl_sefd_s = []\n",
    "    bl_const_x = []\n",
    "    bl_const_s = []\n",
    "    for i1 in range(0, len(SNR_DATA)):\n",
    "        bl = SNR_DATA[i1][0]\n",
    "        sefd_x = []\n",
    "        sefd_s = []\n",
    "        for i2 in range(0, len(antennas_corr_reference)):\n",
    "            if antennas_corr_reference[i2][2] in bl:\n",
    "                for j in range(0, len(stations_SEFD)):\n",
    "                    if antennas_corr_reference[i2][1] in stations_SEFD[j][0]:\n",
    "                        sefd_x.append(stations_SEFD[j][1])\n",
    "                        sefd_s.append(stations_SEFD[j][2])\n",
    "        bl_sefd_x.append(sefd_x)\n",
    "        bl_sefd_s.append(sefd_s)\n",
    "        if SNR_DATA[i1][1] == 0:\n",
    "            const_x = 0#float('NaN')\n",
    "        else: \n",
    "            const_x = (int(sefd_x[0])*int(sefd_x[1]))/snr_data[i1][1]  \n",
    "        if SNR_DATA[i1][3] == 0:\n",
    "            const_s = 0#float('NaN')\n",
    "        else:\n",
    "            const_s = (int(sefd_s[0])*int(sefd_s[1]))/snr_data[i1][3] \n",
    "        bl_const_x.append(const_x)\n",
    "        bl_const_s.append(const_s)\n",
    "        \n",
    "    weights_x = np.sqrt(SNR_DATA[2][:])\n",
    "    weights_x = np.asarray(weights_x)\n",
    "    weights_s = np.sqrt(SNR_DATA[4][:])\n",
    "    weights_s = np.asarray(weights_s)    \n",
    "    return bl_const_x, bl_const_s, weights_x, weights_s\n",
    "    \n",
    "    # This nightmare spaghetti calculates the constant for each baseline combination in the SEFD equation\n",
    "    # This constant is just (SEFD_pred_1 * SEFD_pred_2)/r_snr_12\n",
    "    # also outputs the weightings for the SEFD estimation (sqrt(n))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_s = baselineConstants(snr_data, antennas_corr_reference, stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1037.71266126 1955.22379911 7108.40073159  769.41832449  999.\n",
      " 1478.27137384 2655.38198365 6941.88743134 1223.9327546  4429.54796504\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.        ]\n"
     ]
    }
   ],
   "source": [
    "def sefd_bl_equations(x, SNR_DATA):\n",
    "    # need to set the function up for many of the potential telescopes in the IVS experiments\n",
    "    # The extra variables have no effect if not in the schedule and will instead just have the initial guess value returned.\n",
    "    q, Q, a, K, I, N, X, j, W, i, B, b, d, H, T, E, u, V, Y, R = x\n",
    "    stations = [['q', q],['Q', Q], ['a', a], ['K', K], ['I', I], ['N', N],['X', X], ['j', j], ['W', W], ['i', i], ['B', B], ['b',b], ['d', d], ['H', H], ['T', T], ['E', E], ['u',u], ['V', V], ['Y', Y],['R', R]]    \n",
    "    output = []\n",
    "    for i in range(0, len(SNR_DATA)):\n",
    "        ants = list(SNR_DATA[i][0])\n",
    "        equations = []\n",
    "        for j in range(0, len(stations)):\n",
    "            if stations[j][0] in ants:\n",
    "                equations.append(stations[j][1])\n",
    "        multi = equations[0]*equations[1]\n",
    "        output.append(multi)\n",
    "    output_array = np.asarray(output)\n",
    "    return output_array\n",
    "\n",
    "def system(x,w,SNR_DATA,b):\n",
    "    return w*(sefd_bl_equations(x, SNR_DATA)-b)\n",
    "\n",
    "\n",
    "x0 = 999*np.ones(20)\n",
    "x = scipy.optimize.leastsq(system, x0, args=(weights_s,snr_data,bl_const_s))[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
