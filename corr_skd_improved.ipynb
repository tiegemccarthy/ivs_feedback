{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import MySQLdb as mariadb\n",
    "from astropy.io import ascii\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import scipy.optimize\n",
    "from astropy.table import vstack, Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/19JAN02XA/History/19JAN02XA_V000_kMk4.hist') as file:\n",
    "    contents = file.read()\n",
    "    section = contents.split('+')\n",
    "    \n",
    "with open(os.getcwd()+'/skd_files/r1875.skd') as file:\n",
    "    skd_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on different experiments\n",
    "with open(os.getcwd()+'/NEXT_VERSION_TESTING/corr_files/r1876.corr') as file:\n",
    "    contents = file.read()\n",
    "    section = contents.split('+')\n",
    "    \n",
    "with open(os.getcwd()+'/NEXT_VERSION_TESTING/skd_files/r1876.skd') as file:\n",
    "    skd_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droppedChannels(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    dropped_chans = []\n",
    "    for ant in station_id[1]:\n",
    "        regex = ant + '.*'\n",
    "        dropped = re.findall(regex,text_section,re.MULTILINE)\n",
    "        if dropped == []:\n",
    "            dropped_chans.append('')            \n",
    "        elif len(dropped[0]) < 4:\n",
    "            dropped_chans.append('')\n",
    "        else:\n",
    "            dropped_chans.append(dropped)\n",
    "    return dropped_chans  \n",
    "    # This function takes a block of text, and scrapes out whether any AuScope antennas have dropped channels\n",
    "    # The input of this function is a text section from the correlator report (section[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droppedChannels(section[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualPcal(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    manual_pcal = []\n",
    "    for ant in station_id[1]:\n",
    "        if ant in text_section:\n",
    "            manual_pcal.append(True)\n",
    "        else:\n",
    "            manual_pcal.append(False)\n",
    "    return manual_pcal\n",
    "    # this determines whether manual pcal happened for any of our telescopes.\n",
    "    # The input of this function is a text section from the correlator report (section[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualPcal(section[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "auscope_station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "sefd_stations = ['Hb','Ho','Ke','Yg', 'Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn', 'Hh', 'Ft', 'Ts', 'Wm', 'Ww', 'Wa', 'Wz', 'Bd', 'Ag', 'Ys', 'Ur', 'Sy', 'Oh', 'Tc', 'Ai', 'Cc','Vm','Vs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mask for only the rows that are relevant for auscope antennas\n",
    "col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "snr_data = ascii.read(section[10], data_start=4, fast_reader=True, names=col_names)\n",
    "valid_rows = []\n",
    "for i in range(0, len(snr_data[:]['bl'])):\n",
    "    if any(char in snr_data[i]['bl'] for char in sefd_stations):\n",
    "        valid_rows.append(i)\n",
    "sefd_data = snr_data[valid_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sefdTableExtract(text_section):\n",
    "    #sefd_stations = ['q', 'Q', 'a', 'K', 'I', 'N', 'X', 'j', 'W', 'i', 'B', 'b', 'd', 'H', 'T', 'E', 'u', 'V', 'Y', 'R']\n",
    "    col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "    snr_data = ascii.read(text_section, data_start=4, fast_reader=True, names=col_names)\n",
    "    #valid_rows = []\n",
    "    #for i in range(0, len(snr_data[:]['bl'])):\n",
    "    #    if any(char in snr_data[i]['bl'] for char in sefd_stations):\n",
    "    #        valid_rows.append(i)\n",
    "    #sefd_data = snr_data[valid_rows]\n",
    "    return snr_data\n",
    "    # have moved the check for valid sefd stations into the baseline constant function\n",
    "    \n",
    "    # This extracts the sefd ratio table for any of the 20 telescopes defined in the sefd estimation function.\n",
    "    # Make sure if you change which stations you want to be apart of the calculations, change this sefd_stations\n",
    "    # array and the one in the sefd estimator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HART15M', 'Ht', 'q'],\n",
       " ['KATH12M', 'Ke', 'a'],\n",
       " ['KOKEE', 'Kk', 'K'],\n",
       " ['MATERA', 'Ma', 'I'],\n",
       " ['SEJONG', 'Kv', 'j'],\n",
       " ['WETTZ13N', 'Wn', 'W'],\n",
       " ['YARRA12M', 'Yg', 'i']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = section[4]\n",
    "regex = '^\\s{1}([^\\s].*)'\n",
    "antennas_corr_report = re.findall(regex,contents,re.MULTILINE)\n",
    "\n",
    "antennas_corr_referenceOLD = []\n",
    "for line in antennas_corr_report:\n",
    "    line = line.split()\n",
    "    ref = [line[0], line[1][1:3], line[1][4]]\n",
    "    antennas_corr_referenceOLD.append(ref)\n",
    "\n",
    "antennas_corr_referenceOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ht', 'q'],\n",
       " ['Ke', 'a'],\n",
       " ['Kk', 'K'],\n",
       " ['Ma', 'I'],\n",
       " ['Kv', 'j'],\n",
       " ['Wn', 'W'],\n",
       " ['Yg', 'i']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = section[4]\n",
    "regex = '\\(.{4}\\)'\n",
    "test = re.findall(regex,contents,re.MULTILINE)\n",
    "\n",
    "antennas_corr_reference = []\n",
    "for line in test:\n",
    "    if '/' in line:\n",
    "        ref = [line[1:3],line[4]]\n",
    "        antennas_corr_reference.append(ref)\n",
    "    elif '-' in line:\n",
    "        ref = [line[3:5], line[1]]\n",
    "        antennas_corr_reference.append(ref)\n",
    "\n",
    "antennas_corr_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antennaReference_CORR(text_section):\n",
    "    regex = '\\(.{4}\\)'\n",
    "    antennas_corr_report = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antennas_corr_reference = []\n",
    "    for line in antennas_corr_report:\n",
    "        if '/' in line:\n",
    "            ref = [line[1:3],line[4]]\n",
    "            antennas_corr_reference.append(ref)\n",
    "        elif '-' in line: # this is to handle some funky corr report styles.\n",
    "            ref = [line[3:5], line[1]]\n",
    "            antennas_corr_reference.append(ref)\n",
    "    return antennas_corr_reference\n",
    "    # This function takes the 4th section of the corr report and gives the 2 character\n",
    "    # station code plus the single character corr code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ht', 'q'],\n",
       " ['Ke', 'a'],\n",
       " ['Kk', 'K'],\n",
       " ['Ma', 'I'],\n",
       " ['Kv', 'j'],\n",
       " ['Wn', 'W'],\n",
       " ['Yg', 'i']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antennaReference_CORR(section[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['HART15M', 'Ht', 'Ht'], ['KATH12M', 'Ke', 'Ke'], ['KOKEE', 'Kk', '102'], ['MATERA', 'Ma', '119'], ['SEJONG', 'Kv', 'Kv'], ['WETTZ13N', 'Wn', 'Wn'], ['YARRA12M', 'Yg', 'Yg']]\n"
     ]
    }
   ],
   "source": [
    "regex = \"^A\\s\\s.*\"\n",
    "alias_reference = re.findall(regex,skd_contents,re.MULTILINE)\n",
    "\n",
    "\n",
    "antenna_reference = []\n",
    "for entry in alias_reference:\n",
    "    entry = entry.split()\n",
    "    ref = [entry[2], entry[14], entry[15]]\n",
    "    antenna_reference.append(ref)\n",
    "\n",
    "print(antenna_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antennaReference_SKD(text_section):\n",
    "    regex = \"^A\\s\\s.*\"\n",
    "    alias_reference = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antenna_reference = []\n",
    "    for entry in alias_reference:\n",
    "        entry = entry.split()\n",
    "        ref = [entry[2], entry[14], entry[15]]\n",
    "        antenna_reference.append(ref)\n",
    "    return antenna_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ht', '1400', '1050'], ['Ke', '4800', '4800'], ['Kk', '2000', '750'], ['Ma', '1600', '2200'], ['Kv', '5000', '5000'], ['Wn', '1400', '1050'], ['Yg', '5800', '4300']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regex_sefd = \"^T\\s{3}.*\"\n",
    "sefd_skd = re.findall(regex_sefd,skd_contents,re.MULTILINE)\n",
    "\n",
    "stations_SEFD =[]\n",
    "for line in sefd_skd:\n",
    "    line = line.split()\n",
    "    for i in range(0, len(antenna_reference)):\n",
    "        if line[1] in antenna_reference[i]:\n",
    "            SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "            stations_SEFD.append(SEFD_X_S)\n",
    "print(stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictedSEFDextract(text_section, antenna_reference):\n",
    "    regex_sefd = \"^T\\s{3}.*\"\n",
    "    sefd_skd = re.findall(regex_sefd,text_section,re.MULTILINE)\n",
    "    stations_SEFD =[]\n",
    "    for line in sefd_skd:\n",
    "        line = line.split()\n",
    "        for i in range(0, len(antenna_reference)):\n",
    "            if line[1] in antenna_reference[i]:\n",
    "                SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "                stations_SEFD.append(SEFD_X_S)\n",
    "    return stations_SEFD\n",
    "    # This block of code grabs all the SEFD setting lines and pulls the X and S SEFD for each station.\n",
    "    # It returns a list with each element containing [StationCode, SEFD_X, SEFD_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_sefd_x = []\n",
    "bl_sefd_s = []\n",
    "bl_const_x = []\n",
    "bl_const_s = []\n",
    "for i1 in range(0, len(snr_data)):\n",
    "    bl = snr_data[i1][0]\n",
    "    sefd_x = []\n",
    "    sefd_s = []\n",
    "    for i2 in range(0, len(antennas_corr_reference)):\n",
    "        if antennas_corr_reference[i2][1] in bl:\n",
    "            for j in range(0, len(stations_SEFD)):\n",
    "                if antennas_corr_reference[i2][0] in stations_SEFD[j][0]:\n",
    "                    sefd_x.append(stations_SEFD[j][1])\n",
    "                    sefd_s.append(stations_SEFD[j][2])\n",
    "    bl_sefd_x.append(sefd_x)\n",
    "    bl_sefd_s.append(sefd_s)\n",
    "    if snr_data[i1][1] == 0:\n",
    "        const_x = 0#float('NaN')\n",
    "    else: \n",
    "        const_x = (int(sefd_x[0])*int(sefd_x[1]))/snr_data[i1][1]  \n",
    "    if snr_data[i1][3] == 0:\n",
    "        const_s = 0#float('NaN')\n",
    "    else:\n",
    "        const_s = (int(sefd_s[0])*int(sefd_s[1]))/snr_data[i1][3] \n",
    "    bl_const_x.append(const_x)\n",
    "    bl_const_s.append(const_s)\n",
    "            \n",
    "# This nightmare spaghetti calculates the constant for each baseline combination in the SEFD equation\n",
    "# This constant is just (SEFD_pred_1 * SEFD_pred_2)/r_snr_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=42</i>\n",
       "<table id=\"table139637024488024\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>bl</th><th>X_snr</th><th>X_n</th><th>S_snr</th><th>S_n</th></tr></thead>\n",
       "<thead><tr><th>str2</th><th>float64</th><th>int64</th><th>float64</th><th>int64</th></tr></thead>\n",
       "<tr><td>qa</td><td>0.34</td><td>113</td><td>0.65</td><td>142</td></tr>\n",
       "<tr><td>qK</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td></tr>\n",
       "<tr><td>qI</td><td>0.53</td><td>313</td><td>0.75</td><td>319</td></tr>\n",
       "<tr><td>qj</td><td>1.42</td><td>82</td><td>0.69</td><td>76</td></tr>\n",
       "<tr><td>qW</td><td>0.69</td><td>282</td><td>0.92</td><td>313</td></tr>\n",
       "<tr><td>qi</td><td>1.05</td><td>235</td><td>1.01</td><td>235</td></tr>\n",
       "<tr><td>aK</td><td>0.33</td><td>124</td><td>0.65</td><td>159</td></tr>\n",
       "<tr><td>aI</td><td>0.23</td><td>32</td><td>0.54</td><td>66</td></tr>\n",
       "<tr><td>aj</td><td>0.56</td><td>169</td><td>0.49</td><td>117</td></tr>\n",
       "<tr><td>aW</td><td>0.27</td><td>33</td><td>0.55</td><td>81</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>KI</td><td>0.56</td><td>106</td><td>1.01</td><td>110</td></tr>\n",
       "<tr><td>Kj</td><td>1.62</td><td>235</td><td>0.75</td><td>232</td></tr>\n",
       "<tr><td>KW</td><td>0.69</td><td>155</td><td>0.81</td><td>180</td></tr>\n",
       "<tr><td>Ki</td><td>1.11</td><td>115</td><td>1.06</td><td>114</td></tr>\n",
       "<tr><td>Ij</td><td>1.03</td><td>153</td><td>0.54</td><td>118</td></tr>\n",
       "<tr><td>IW</td><td>0.58</td><td>457</td><td>0.64</td><td>471</td></tr>\n",
       "<tr><td>Ii</td><td>0.64</td><td>120</td><td>0.76</td><td>116</td></tr>\n",
       "<tr><td>jW</td><td>1.09</td><td>163</td><td>0.52</td><td>143</td></tr>\n",
       "<tr><td>ji</td><td>1.68</td><td>173</td><td>0.69</td><td>170</td></tr>\n",
       "<tr><td>Wi</td><td>0.74</td><td>97</td><td>0.86</td><td>108</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=42>\n",
       " bl   X_snr   X_n   S_snr   S_n \n",
       "str2 float64 int64 float64 int64\n",
       "---- ------- ----- ------- -----\n",
       "  qa    0.34   113    0.65   142\n",
       "  qK     0.0     0     0.0     0\n",
       "  qI    0.53   313    0.75   319\n",
       "  qj    1.42    82    0.69    76\n",
       "  qW    0.69   282    0.92   313\n",
       "  qi    1.05   235    1.01   235\n",
       "  aK    0.33   124    0.65   159\n",
       "  aI    0.23    32    0.54    66\n",
       "  aj    0.56   169    0.49   117\n",
       "  aW    0.27    33    0.55    81\n",
       " ...     ...   ...     ...   ...\n",
       "  KI    0.56   106    1.01   110\n",
       "  Kj    1.62   235    0.75   232\n",
       "  KW    0.69   155    0.81   180\n",
       "  Ki    1.11   115    1.06   114\n",
       "  Ij    1.03   153    0.54   118\n",
       "  IW    0.58   457    0.64   471\n",
       "  Ii    0.64   120    0.76   116\n",
       "  jW    1.09   163    0.52   143\n",
       "  ji    1.68   173    0.69   170\n",
       "  Wi    0.74    97    0.86   108"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_data_stacked = vstack([snr_data,snr_data])\n",
    "snr_data_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD):\n",
    "    bl_sefd_x = []\n",
    "    bl_sefd_s = []\n",
    "    bl_const_x = []\n",
    "    bl_const_s = []\n",
    "    weights_x = []\n",
    "    weights_s = []\n",
    "    sefd_stations = ['Ke','Yg', 'Hb', 'Ho', 'Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn', 'Hh', 'Ft', 'Ts', 'Wm', 'Ww', 'Wa', 'Wz', 'Bd', 'Ag', 'Ys', 'Ur', 'Sy', 'Oh', 'Tc', 'Ai', 'Cc','Vm','Vs']\n",
    "    for i1 in range(0, len(SNR_DATA)):\n",
    "        bl = list(SNR_DATA[i1][0])\n",
    "        sefd_x = []\n",
    "        sefd_s = []\n",
    "        for i2 in range(0, len(antennas_corr_reference)):\n",
    "            if antennas_corr_reference[i2][0] in sefd_stations and antennas_corr_reference[i2][1] in bl:\n",
    "                for j in range(0, len(stations_SEFD)):\n",
    "                    if antennas_corr_reference[i2][0] == stations_SEFD[j][0]: # probably a more elegant way to do this with list.index()\n",
    "                        sefd_x.append(stations_SEFD[j][1])\n",
    "                        sefd_s.append(stations_SEFD[j][2])\n",
    "        if len(sefd_x) > 1: # this checks that 2 valid telescopes are in the bl\n",
    "            bl_sefd_x.append(sefd_x)\n",
    "            bl_sefd_s.append(sefd_s)\n",
    "            if SNR_DATA[i1][1] == 0:\n",
    "                const_x = 0#float('NaN')\n",
    "            else: \n",
    "                const_x = (int(sefd_x[0])*int(sefd_x[1]))/SNR_DATA[i1][1]  \n",
    "            if SNR_DATA[i1][3] == 0:\n",
    "                const_s = 0#float('NaN')\n",
    "            else:\n",
    "                const_s = (int(sefd_s[0])*int(sefd_s[1]))/SNR_DATA[i1][3] \n",
    "            bl_const_x.append(const_x)\n",
    "            bl_const_s.append(const_s)\n",
    "            w_x = np.sqrt(SNR_DATA[i1][2])\n",
    "            w_s = np.sqrt(SNR_DATA[i1][4])\n",
    "            weights_x.append(w_x)\n",
    "            weights_s.append(w_s)\n",
    "    weights_x = np.asarray(weights_x)\n",
    "    weights_s = np.asarray(weights_s)    \n",
    "    return bl_const_x, bl_const_s, weights_x, weights_s\n",
    "    \n",
    "    # This nightmare spaghetti calculates the constant for each baseline combination in the SEFD equation\n",
    "    # This constant is just (SEFD_pred_1 * SEFD_pred_2)/r_snr_12\n",
    "    # also outputs the weightings for the SEFD estimation (sqrt(n)).\n",
    "    # It is important that the sefd_station list is the same as the list of stations in the\n",
    "    # sefd estimation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_const_x, bl_const_s, weights_x, weights_s = baselineConstantsWeights(snr_data, antennas_corr_reference, stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1056.78059566  999.         7149.91186081  731.06504773 2833.06924189\n",
      "  999.          999.         6900.33884805 1331.99144709 4546.7486793\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.        ]\n"
     ]
    }
   ],
   "source": [
    "def sefd_bl_equations(x, SNR_DATA):\n",
    "    # need to set the function up for many of the potential telescopes in the IVS experiments\n",
    "    # The extra variables have no effect if not in the schedule and will instead just have the initial guess value returned.\n",
    "    q, Q, a, K, I, N, X, j, W, i, B, b, d, H, T, E, u, V, Y, R = x\n",
    "    stations = [['q', q],['Q', Q], ['a', a], ['K', K], ['I', I], ['N', N],['X', X], ['j', j], ['W', W], ['i', i], ['B', B], ['b',b], ['d', d], ['H', H], ['T', T], ['E', E], ['u',u], ['V', V], ['Y', Y],['R', R]]    \n",
    "    output = []\n",
    "    for i in range(0, len(SNR_DATA)):\n",
    "        ants = list(SNR_DATA[i][0])\n",
    "        equations = []\n",
    "        for j in range(0, len(stations)):\n",
    "            if stations[j][0] in ants:\n",
    "                equations.append(stations[j][1])\n",
    "        multi = equations[0]*equations[1]\n",
    "        output.append(multi)\n",
    "    output_array = np.asarray(output)\n",
    "    return output_array\n",
    "\n",
    "def system(x,w,SNR_DATA,b):\n",
    "    return w*(sefd_bl_equations(x, SNR_DATA)-b)\n",
    "\n",
    "\n",
    "x0 = 999*np.ones(20)\n",
    "x = scipy.optimize.leastsq(system, x0, args=(weights_s,snr_data,bl_const_s))[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to make this code work for all corr reports..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to try and define the baselines in terms of the two letter codes rather than the 1 letter codes that change depending on correlator.\n",
    "\n",
    "This should be possible by just changing the stations list in the sefd_bl_equations() function to two letter codes that have a correpsonding x variables (x1, x2, ...), then using the antennas_corr_ref list to translate between the codes used for a particular correlator (e.g a, q, i etc.) into the two letter codes, which in turn will add the corresponding x variables into the system of equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7149.91186115 4546.74867895  999.          999.         1056.78059596\n",
      "  999.          731.06504767 2833.06924242  999.          999.\n",
      " 6900.33884803 1331.99144707  999.          999.          999.\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.        ]\n"
     ]
    }
   ],
   "source": [
    "def sefd_bl_equations(x, SNR_DATA, antennas_corr_reference):\n",
    "    # need to set the function up for many of the potential telescopes in the IVS experiments\n",
    "    # The extra variables have no effect if not in the schedule and will instead just have the initial guess value returned.\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30 = x\n",
    "    #stations = [['Hb', x1],['Ho', x2], ['Ke', x3], ['Yg', x4], ['Ht', x5], ['Is', x6],['Kk', x7], ['Ma', x8], ['Ny', x9], ['On', x10], ['Kv', x11] , ['Wn', x12]]    \n",
    "    station_str = ['Ke','Yg', 'Hb', 'Ho','Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn', 'Hh', 'Ft', 'Ts', 'Wm', 'Ww', 'Wa', 'Wz', 'Bd', 'Ag', 'Ys', 'Ur', 'Sy', 'Oh', 'Tc', 'Ai', 'Cc','Vm','Vs']\n",
    "    station_var = [x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30]\n",
    "    output = []\n",
    "    for i in range(0, len(SNR_DATA)):\n",
    "        ants = list(SNR_DATA[i][0])\n",
    "        equations = []\n",
    "        for j in range(0, len(antennas_corr_reference)):\n",
    "            if antennas_corr_reference[j][1] in ants and antennas_corr_reference[j][0] in station_str:\n",
    "                equations.append(station_var[station_str.index(antennas_corr_reference[j][0])])\n",
    "        if len(equations) > 1:  \n",
    "            multi = equations[0]*equations[1]\n",
    "            output.append(multi)\n",
    "    output_array = np.asarray(output)\n",
    "    return output_array\n",
    "\n",
    "def system(x,w,SNR_DATA,antennas_corr_reference,b):\n",
    "    return w*(sefd_bl_equations(x, SNR_DATA, antennas_corr_reference)-b)\n",
    "\n",
    "\n",
    "x0 = 999*np.ones(30)\n",
    "x = scipy.optimize.leastsq(system, x0, args=(weights_s,snr_data_stacked,antennas_corr_reference,bl_const_s))[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function now works for calculating the SEFD of any experiment in that 30 antenna list.\n",
    "\n",
    "Need to make sure that only baselines with telescopes in that 30 get fed into this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableLengthHacker(SNR_DATA, antennas_corr_reference, stations_SEFD):\n",
    "    # This function is purely to deal with the fact that my SEFD estimation system can't handle cases \n",
    "    # where there are less equations generated than the number of defined antennas (30). It simply\n",
    "    # stacks the snr_data table so the generated equations are 30 or more. This does not do anything to the\n",
    "    # values because every equation is just occuring N times, so the increase in weighting is equal. It simply\n",
    "    # bypasses the shortcomings of doing this in python.\n",
    "    bl_const_x, bl_const_s, weights_x, weights_s = baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD)\n",
    "    while len(bl_const_x) < 30:\n",
    "        SNR_DATA = vstack([SNR_DATA,SNR_DATA])\n",
    "        bl_const_x, bl_const_s, weights_x, weights_s = baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD)\n",
    "    return bl_const_x, bl_const_s, weights_x, weights_s, SNR_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_const_x, bl_const_s, weights_x, weights_s, snr_data_stacked = tableLengthHacker(snr_data, antennas_corr_reference, stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "antennas_corr_reference#.index('Ht')\n",
    "stations_str = ['Hb','Ho','Ke','Yg', 'Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn']    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = [\"Ke\", \"Yg\", \"Hb\", \"Ho\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_station = \"UPDATE {} SET (estSEFD_X, estSEFD_S, Manual_Pcal, Dropped_Chans) VALUES (%s, %s, %s, %s) WHERE ExpID={};\".format(station_id[0], 'R1875')\n",
    "data = [9999.99, 10000.99, True, 'test test', 'r1875']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_station = \"\"\"\n",
    "    UPDATE {}\n",
    "    SET estSEFD_X=%s, estSEFD_S=%s, Manual_Pcal=%s, Dropped_Chans=%s\n",
    "    WHERE ExpID = %s\n",
    "\"\"\".format(station_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    UPDATE Ke\\n    SET estSEFD_X=%s, estSEFD_S=%s, Manual_Pcal=%s, Dropped_Chans=%s\\n    WHERE ExpID = %s\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'auscope_test2'\n",
    "conn = mariadb.connect(user='auscope', passwd='password', db=str(db_name))\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_station, data)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
