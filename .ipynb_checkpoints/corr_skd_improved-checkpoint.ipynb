{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import MySQLdb as mariadb\n",
    "from astropy.io import ascii\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import scipy.optimize\n",
    "from astropy.table import vstack, Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.getcwd()+'/19JAN02XA/History/19JAN02XA_V000_kMk4.hist') as file:\n",
    "    contents = file.read()\n",
    "    section = contents.split('\\n+')\n",
    "    \n",
    "with open(os.getcwd()+'/skd_files/r1875.skd') as file:\n",
    "    skd_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on different experiments\n",
    "with open(os.getcwd()+'/NEXT_VERSION_TESTING/corr_files/aov032.corr') as file:\n",
    "    contents = file.read()\n",
    "    section = contents.split('\\n+')\n",
    "    if len(section) < 13:\n",
    "        section = contents.split('\\n +')\n",
    "    \n",
    "with open(os.getcwd()+'/NEXT_VERSION_TESTING/skd_files/aov032.skd') as file:\n",
    "    skd_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def droppedChannels(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    dropped_chans = []\n",
    "    for ant in station_id[1]:\n",
    "        regex = ant + '.*'\n",
    "        dropped = re.findall(regex,text_section,re.MULTILINE)\n",
    "        if dropped == []:\n",
    "            dropped_chans.append('')            \n",
    "        elif len(dropped[0]) < 4:\n",
    "            dropped_chans.append('')\n",
    "        else:\n",
    "            dropped_chans.append(dropped)\n",
    "    return dropped_chans  \n",
    "    # This function takes a block of text, and scrapes out whether any AuScope antennas have dropped channels\n",
    "    # The input of this function is a text section from the correlator report (section[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droppedChannels(section[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualPcal(text_section):\n",
    "    station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "    manual_pcal = []\n",
    "    for ant in station_id[1]:\n",
    "        if ant in text_section:\n",
    "            manual_pcal.append(True)\n",
    "        else:\n",
    "            manual_pcal.append(False)\n",
    "    return manual_pcal\n",
    "    # this determines whether manual pcal happened for any of our telescopes.\n",
    "    # The input of this function is a text section from the correlator report (section[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualPcal(section[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "auscope_station_id = [['KATH12M', 'YARRA12M', 'HOBART12', 'HOBART26'], ['Ke', 'Yg', 'Hb', 'Ho'], ['a', 'i', 'd', 'H']]\n",
    "sefd_stations = ['Hb','Ho','Ke','Yg', 'Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn', 'Hh', 'Ft', 'Ts', 'Wm', 'Ww', 'Wa', 'Wz', 'Bd', 'Ag', 'Ys', 'Ur', 'Sy', 'Oh', 'Tc', 'Ai', 'Cc','Vm','Vs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mask for only the rows that are relevant for auscope antennas\n",
    "col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "snr_data = ascii.read(section[10], data_start=4, fast_reader=True, names=col_names)\n",
    "valid_rows = []\n",
    "for i in range(0, len(snr_data[:]['bl'])):\n",
    "    if any(char in snr_data[i]['bl'] for char in sefd_stations):\n",
    "        valid_rows.append(i)\n",
    "sefd_data = snr_data[valid_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1537"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sefdTableExtract(text_section):\n",
    "    if len(text_section) > 20:\n",
    "        col_names = ['bl', 'X_snr', 'X_n', 'S_snr', 'S_n']\n",
    "        snr_data = ascii.read(text_section, data_start=4, fast_reader=True, names=col_names)\n",
    "    else: \n",
    "        snr_data = []\n",
    "        # if snr table isnt included for some reason, this stops the script from crashing.\n",
    "        # Instead SEFD estimation will be skipped.\n",
    "    return snr_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr_data = sefdTableExtract(section[10])\n",
    "len(snr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HART15M', 'Ht', 'q'],\n",
       " ['ISHIOKA', 'Is', 'Q'],\n",
       " ['KATH12M', 'Ke', 'a'],\n",
       " ['KOKEE', 'Kk', 'K'],\n",
       " ['MATERA', 'Ma', 'I'],\n",
       " ['NYALES20', 'Ny', 'N'],\n",
       " ['ONSALA60', 'On', 'X'],\n",
       " ['SEJONG', 'Kv', 'j'],\n",
       " ['WETTZ13N', 'Wn', 'W'],\n",
       " ['YARRA12M', 'Yg', 'i']]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = section[4]\n",
    "regex = '^\\s{1}([^\\s].*)'\n",
    "antennas_corr_report = re.findall(regex,contents,re.MULTILINE)\n",
    "\n",
    "antennas_corr_referenceOLD = []\n",
    "for line in antennas_corr_report:\n",
    "    line = line.split()\n",
    "    ref = [line[0], line[1][1:3], line[1][4]]\n",
    "    antennas_corr_referenceOLD.append(ref)\n",
    "\n",
    "antennas_corr_referenceOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ht', 'q'],\n",
       " ['Is', 'Q'],\n",
       " ['Ke', 'a'],\n",
       " ['Kk', 'K'],\n",
       " ['Ma', 'I'],\n",
       " ['Ny', 'N'],\n",
       " ['On', 'X'],\n",
       " ['Kv', 'j'],\n",
       " ['Wn', 'W'],\n",
       " ['Yg', 'i']]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents = section[4]\n",
    "regex = '\\(.{4}\\)'\n",
    "test = re.findall(regex,contents,re.MULTILINE)\n",
    "\n",
    "antennas_corr_reference = []\n",
    "for line in test:\n",
    "    if '/' in line:\n",
    "        ref = [line[1:3],line[4]]\n",
    "        antennas_corr_reference.append(ref)\n",
    "    elif '-' in line:\n",
    "        ref = [line[3:5], line[1]]\n",
    "        antennas_corr_reference.append(ref)\n",
    "\n",
    "antennas_corr_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antennaReference_CORR(text_section):\n",
    "    regex = '\\(.{4}\\)'\n",
    "    antennas_corr_report = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antennas_corr_reference = []\n",
    "    for line in antennas_corr_report:\n",
    "        if '/' in line:\n",
    "            ref = [line[1:3],line[4]]\n",
    "            antennas_corr_reference.append(ref)\n",
    "        elif '-' in line: # this is to handle some funky corr report styles.\n",
    "            ref = [line[3:5], line[1]]\n",
    "            antennas_corr_reference.append(ref)\n",
    "    return antennas_corr_reference\n",
    "    # This function takes the 4th section of the corr report and gives the 2 character\n",
    "    # station code plus the single character corr code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Ht', 'q'],\n",
       " ['Is', 'Q'],\n",
       " ['Ke', 'a'],\n",
       " ['Kk', 'K'],\n",
       " ['Ma', 'I'],\n",
       " ['Ny', 'N'],\n",
       " ['On', 'X'],\n",
       " ['Kv', 'j'],\n",
       " ['Wn', 'W'],\n",
       " ['Yg', 'i']]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antennaReference_CORR(section[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['HART15M', 'Ht', 'Ht'], ['ISHIOKA', 'Is', 'Is'], ['KATH12M', 'Ke', 'Ke'], ['KOKEE', 'Kk', '102'], ['MATERA', 'Ma', '119'], ['NYALES20', 'Ny', '66'], ['ONSALA60', 'On', '02'], ['SEJONG', 'Kv', 'Kv'], ['WETTZ13N', 'Wn', 'Wn'], ['YARRA12M', 'Yg', 'Yg']]\n"
     ]
    }
   ],
   "source": [
    "regex = \"^A\\s\\s.*\"\n",
    "alias_reference = re.findall(regex,skd_contents,re.MULTILINE)\n",
    "\n",
    "\n",
    "antenna_reference = []\n",
    "for entry in alias_reference:\n",
    "    entry = entry.split()\n",
    "    ref = [entry[2], entry[14], entry[15]]\n",
    "    antenna_reference.append(ref)\n",
    "\n",
    "print(antenna_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def antennaReference_SKD(text_section):\n",
    "    regex = \"^A\\s\\s.*\"\n",
    "    alias_reference = re.findall(regex,text_section,re.MULTILINE)\n",
    "    antenna_reference = []\n",
    "    for entry in alias_reference:\n",
    "        entry = entry.split()\n",
    "        ref = [entry[2], entry[14], entry[15]]\n",
    "        antenna_reference.append(ref)\n",
    "    return antenna_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ht', '1400', '1050'], ['Is', '1950', '1750'], ['Ke', '4800', '4800'], ['Kk', '2000', '750'], ['Ma', '1600', '2200'], ['Ny', '1000', '1500'], ['On', '2000', '2500'], ['Kv', '5000', '5000'], ['Wn', '1400', '1050'], ['Yg', '5800', '4300']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regex_sefd = \"^T\\s{2}.*\"\n",
    "sefd_skd = re.findall(regex_sefd,skd_contents,re.MULTILINE)\n",
    "\n",
    "stations_SEFD =[]\n",
    "for line in sefd_skd:\n",
    "    line = line.split()\n",
    "    for i in range(0, len(antenna_reference)):\n",
    "        if line[1] in antenna_reference[i]:\n",
    "            SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "            stations_SEFD.append(SEFD_X_S)\n",
    "print(stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictedSEFDextract(text_section, antenna_reference):\n",
    "    regex_sefd = \"^T\\s{2}.*\"\n",
    "    sefd_skd = re.findall(regex_sefd,text_section,re.MULTILINE)\n",
    "    stations_SEFD =[]\n",
    "    for line in sefd_skd:\n",
    "        line = line.split()\n",
    "        for i in range(0, len(antenna_reference)):\n",
    "            if line[1] in antenna_reference[i]:\n",
    "                SEFD_X_S = [antenna_reference[i][1], line[6], line[8]]\n",
    "                stations_SEFD.append(SEFD_X_S)\n",
    "    return stations_SEFD\n",
    "    # This block of code grabs all the SEFD setting lines and pulls the X and S SEFD for each station.\n",
    "    # It returns a list with each element containing [StationCode, SEFD_X, SEFD_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_sefd_x = []\n",
    "bl_sefd_s = []\n",
    "bl_const_x = []\n",
    "bl_const_s = []\n",
    "for i1 in range(0, len(snr_data)):\n",
    "    bl = snr_data[i1][0]\n",
    "    sefd_x = []\n",
    "    sefd_s = []\n",
    "    for i2 in range(0, len(antennas_corr_reference)):\n",
    "        if antennas_corr_reference[i2][1] in bl:\n",
    "            for j in range(0, len(stations_SEFD)):\n",
    "                if antennas_corr_reference[i2][0] in stations_SEFD[j][0]:\n",
    "                    sefd_x.append(stations_SEFD[j][1])\n",
    "                    sefd_s.append(stations_SEFD[j][2])\n",
    "    bl_sefd_x.append(sefd_x)\n",
    "    bl_sefd_s.append(sefd_s)\n",
    "    if snr_data[i1][1] == 0:\n",
    "        const_x = 0#float('NaN')\n",
    "    else: \n",
    "        const_x = (int(sefd_x[0])*int(sefd_x[1]))/snr_data[i1][1]  \n",
    "    if snr_data[i1][3] == 0:\n",
    "        const_s = 0#float('NaN')\n",
    "    else:\n",
    "        const_s = (int(sefd_s[0])*int(sefd_s[1]))/snr_data[i1][3] \n",
    "    bl_const_x.append(const_x)\n",
    "    bl_const_s.append(const_s)\n",
    "            \n",
    "# This nightmare spaghetti calculates the constant for each baseline combination in the SEFD equation\n",
    "# This constant is just (SEFD_pred_1 * SEFD_pred_2)/r_snr_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD):\n",
    "    bl_sefd_x = []\n",
    "    bl_sefd_s = []\n",
    "    bl_const_x = []\n",
    "    bl_const_s = []\n",
    "    weights_x = []\n",
    "    weights_s = []\n",
    "    bl_list = []\n",
    "    sefd_stations = ['Ke','Yg', 'Hb', 'Ho','Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn', 'Hh', 'Ft', 'Ts', 'Wm', 'Ww', 'Wa', 'Wz', 'Bd', 'Ag', 'Ys', 'Ur', 'Sy', 'Oh', 'Tc', 'Ai', 'Cc','Vm','Vs']\n",
    "    for i1 in range(0, len(SNR_DATA)):\n",
    "        bl = list(SNR_DATA[i1][0])\n",
    "        sefd_x = []\n",
    "        sefd_s = []\n",
    "        for i2 in range(0, len(antennas_corr_reference)):\n",
    "            if antennas_corr_reference[i2][0] in sefd_stations and antennas_corr_reference[i2][1] in bl:\n",
    "                for j in range(0, len(stations_SEFD)):\n",
    "                    if antennas_corr_reference[i2][0] == stations_SEFD[j][0]: # probably a more elegant way to do this with list.index()\n",
    "                        sefd_x.append(stations_SEFD[j][1])\n",
    "                        sefd_s.append(stations_SEFD[j][2])\n",
    "        if len(sefd_x) > 1: # this checks that 2 valid telescopes are in the bl\n",
    "            bl_sefd_x.append(sefd_x)\n",
    "            bl_sefd_s.append(sefd_s)\n",
    "            if SNR_DATA[i1][1] == 0:\n",
    "                const_x = 0#float('NaN')\n",
    "            else: \n",
    "                const_x = (int(sefd_x[0])*int(sefd_x[1]))/SNR_DATA[i1][1]  \n",
    "            if SNR_DATA[i1][3] == 0:\n",
    "                const_s = 0#float('NaN')\n",
    "            else:\n",
    "                const_s = (int(sefd_s[0])*int(sefd_s[1]))/SNR_DATA[i1][3] \n",
    "            bl_const_x.append(const_x)\n",
    "            bl_const_s.append(const_s)\n",
    "            w_x = np.sqrt(SNR_DATA[i1][2])\n",
    "            w_s = np.sqrt(SNR_DATA[i1][4])\n",
    "            weights_x.append(w_x)\n",
    "            weights_s.append(w_s)\n",
    "            bl_list.append(SNR_DATA[i1][0])\n",
    "    weights_x = np.asarray(weights_x)\n",
    "    weights_s = np.asarray(weights_s)    \n",
    "    return bl_const_x, bl_const_s, weights_x, weights_s, bl_list\n",
    "    \n",
    "    # This nightmare spaghetti calculates the constant for each baseline combination in the SEFD equation\n",
    "    # This constant is just (SEFD_pred_1 * SEFD_pred_2)/r_snr_12\n",
    "    # also outputs the weightings for the SEFD estimation (sqrt(n)).\n",
    "    # It is important that the sefd_station list is the same as the list of stations in the\n",
    "    # sefd estimation system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableLengthHacker(SNR_DATA, antennas_corr_reference, stations_SEFD):\n",
    "    # This function is purely to deal with the fact that my SEFD estimation system can't handle cases \n",
    "    # where there are less equations generated than the number of defined antennas (30). It simply\n",
    "    # stacks the snr_data table so the generated equations are 30 or more. This does not do anything to the\n",
    "    # values because every equation is just occuring N times, so the increase in weighting is equal. It simply\n",
    "    # bypasses the shortcomings of doing this in python.\n",
    "    bl_const_x, bl_const_s, weights_x, weights_s, bl_list = baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD)\n",
    "    if len(SNR_DATA) > 1:\n",
    "        while len(bl_const_x) < 30:\n",
    "            SNR_DATA = vstack([SNR_DATA,SNR_DATA])\n",
    "            bl_const_x, bl_const_s, weights_x, weights_s, bl_list = baselineConstantsWeights(SNR_DATA, antennas_corr_reference, stations_SEFD)\n",
    "    return bl_const_x, bl_const_s, weights_x, weights_s, bl_list, SNR_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_const_x, bl_const_s, weights_x, weights_s, bl_list = baselineConstantsWeights(snr_data, antennas_corr_reference, stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_const_x, bl_const_s, weights_x, weights_s, bl_list, snr_data_stacked = tableLengthHacker(snr_data, antennas_corr_reference, stations_SEFD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qQ',\n",
       " 'qa',\n",
       " 'qK',\n",
       " 'qI',\n",
       " 'qN',\n",
       " 'qX',\n",
       " 'qj',\n",
       " 'qW',\n",
       " 'qi',\n",
       " 'Qa',\n",
       " 'QK',\n",
       " 'QI',\n",
       " 'QN',\n",
       " 'QX',\n",
       " 'Qj',\n",
       " 'QW',\n",
       " 'Qi',\n",
       " 'aK',\n",
       " 'aI',\n",
       " 'aN',\n",
       " 'aX',\n",
       " 'aj',\n",
       " 'aW',\n",
       " 'ai',\n",
       " 'KI',\n",
       " 'KN',\n",
       " 'KX',\n",
       " 'Kj',\n",
       " 'KW',\n",
       " 'Ki',\n",
       " 'IN',\n",
       " 'IX',\n",
       " 'Ij',\n",
       " 'IW',\n",
       " 'Ii',\n",
       " 'NX',\n",
       " 'Nj',\n",
       " 'NW',\n",
       " 'Ni',\n",
       " 'Xj',\n",
       " 'XW',\n",
       " 'Xi',\n",
       " 'jW',\n",
       " 'ji',\n",
       " 'Wi']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1037.71266126 1955.22379911 7108.40073159  769.41832449  999.\n",
      " 1478.27137384 2655.38198365 6941.88743134 1223.9327546  4429.54796504\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.        ]\n"
     ]
    }
   ],
   "source": [
    "def sefd_bl_equations(x, SNR_DATA):\n",
    "    # need to set the function up for many of the potential telescopes in the IVS experiments\n",
    "    # The extra variables have no effect if not in the schedule and will instead just have the initial guess value returned.\n",
    "    q, Q, a, K, I, N, X, j, W, i, B, b, d, H, T, E, u, V, Y, R = x\n",
    "    stations = [['q', q],['Q', Q], ['a', a], ['K', K], ['I', I], ['N', N],['X', X], ['j', j], ['W', W], ['i', i], ['B', B], ['b',b], ['d', d], ['H', H], ['T', T], ['E', E], ['u',u], ['V', V], ['Y', Y],['R', R]]    \n",
    "    output = []\n",
    "    for i in range(0, len(SNR_DATA)):\n",
    "        ants = list(SNR_DATA[i][0])\n",
    "        equations = []\n",
    "        for j in range(0, len(stations)):\n",
    "            if stations[j][0] in ants:\n",
    "                equations.append(stations[j][1])\n",
    "        multi = equations[0]*equations[1]\n",
    "        output.append(multi)\n",
    "    output_array = np.asarray(output)\n",
    "    return output_array\n",
    "\n",
    "def system(x,w,SNR_DATA,b):\n",
    "    return w*(sefd_bl_equations(x, SNR_DATA)-b)\n",
    "\n",
    "\n",
    "x0 = 999*np.ones(20)\n",
    "x = scipy.optimize.leastsq(system, x0, args=(weights_s,snr_data,bl_const_s))[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempting to make this code work for all corr reports..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to try and define the baselines in terms of the two letter codes rather than the 1 letter codes that change depending on correlator.\n",
    "\n",
    "This should be possible by just changing the stations list in the sefd_bl_equations() function to two letter codes that have a correpsonding x variables (x1, x2, ...), then using the antennas_corr_ref list to translate between the codes used for a particular correlator (e.g a, q, i etc.) into the two letter codes, which in turn will add the corresponding x variables into the system of equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7108.40073159 4429.54796504  999.          999.         1037.71266126\n",
      " 1955.22379911  769.41832449  999.         1478.27137384 2655.38198365\n",
      " 6941.88743134 1223.9327546   999.          999.          999.\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.\n",
      "  999.          999.          999.          999.          999.        ]\n"
     ]
    }
   ],
   "source": [
    "def sefd_bl_equations(x, bl_list, antennas_corr_reference):\n",
    "    # need to set the function up for many of the potential telescopes in the IVS experiments\n",
    "    # The extra variables have no effect if not in the schedule and will instead just have the initial guess value returned.\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30 = x\n",
    "    #stations = [['Hb', x1],['Ho', x2], ['Ke', x3], ['Yg', x4], ['Ht', x5], ['Is', x6],['Kk', x7], ['Ma', x8], ['Ny', x9], ['On', x10], ['Kv', x11] , ['Wn', x12]]    \n",
    "    station_str = ['Ke','Yg', 'Hb', 'Ho','Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn', 'Hh', 'Ft', 'Ts', 'Wm', 'Ww', 'Wa', 'Wz', 'Bd', 'Ag', 'Ys', 'Ur', 'Sy', 'Oh', 'Tc', 'Ai', 'Cc','Vm','Vs']\n",
    "    station_var = [x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30]\n",
    "    output = []\n",
    "    for i in range(0, len(bl_list)):\n",
    "        ants = list(bl_list[i])\n",
    "        equations = []\n",
    "        for j in range(0, len(antennas_corr_reference)):\n",
    "            if antennas_corr_reference[j][1] in ants and antennas_corr_reference[j][0] in station_str:\n",
    "                equations.append(station_var[station_str.index(antennas_corr_reference[j][0])])\n",
    "        if len(equations) > 1:  \n",
    "            multi = equations[0]*equations[1]\n",
    "            output.append(multi)\n",
    "    output_array = np.asarray(output)\n",
    "    return output_array\n",
    "\n",
    "def system(x,w,bl_list,antennas_corr_reference,b):\n",
    "    return w*(sefd_bl_equations(x, bl_list, antennas_corr_reference)-b)\n",
    "\n",
    "\n",
    "x0 = 999*np.ones(30)\n",
    "x = scipy.optimize.leastsq(system, x0, args=(weights_s,bl_list,antennas_corr_reference,bl_const_s))[0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function now works for calculating the SEFD of any experiment in that 30 antenna list.\n",
    "\n",
    "Need to make sure that only baselines with telescopes in that 30 get fed into this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bl_const_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "antennas_corr_reference#.index('Ht')\n",
    "stations_str = ['Hb','Ho','Ke','Yg', 'Ht', 'Is', 'Kk', 'Ma', 'Ny', 'On', 'Kv', 'Wn']    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = [\"Ke\", \"Yg\", \"Hb\", \"Ho\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_station = \"UPDATE {} SET (estSEFD_X, estSEFD_S, Manual_Pcal, Dropped_Chans) VALUES (%s, %s, %s, %s) WHERE ExpID={};\".format(station_id[0], 'R1875')\n",
    "data =  [False, 'test2', 'crds99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_station = \"\"\"\n",
    "    UPDATE {}\n",
    "    SET Manual_Pcal=%s, Dropped_Chans=%s\n",
    "    WHERE ExpID = %s\n",
    "\"\"\".format(station_id[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    UPDATE Ho\\n    SET Manual_Pcal=%s, Dropped_Chans=%s\\n    WHERE ExpID = %s\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(station_id)):\n",
    "    sql_station = \"\"\"\n",
    "        UPDATE {}\n",
    "        SET Manual_Pcal=%s, Dropped_Chans=%s\n",
    "        WHERE ExpID = %s;\n",
    "    \"\"\".format(station_id[i])\n",
    "    db_name = 'auscope_test2'\n",
    "    conn = mariadb.connect(user='auscope', passwd='password', db=str(db_name))\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql_station, data)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
